import sys
import os
import time
from datetime import datetime
import cv2
import torch
import numpy as np

from PyQt5.QtWidgets import QApplication, QMainWindow, QTableWidgetItem, QLabel
from PyQt5.QtGui import QImage, QPixmap
from PyQt5.QtCore import Qt, QThread, pyqtSignal

# åŒ¯å…¥æˆ‘å€‘çš„æ¨¡çµ„
from ui import PCBAUIInterface
from yolo_inference import YOLOv12Detector
from camera_capture import capture_image
from conveyor_control import ConveyorControl
from robot_arm_control import RobotArmControl

# ======================================================================
# --- å…¨å±€é…ç½® ---
# ======================================================================
# --- æ¨¡å‹é…ç½® ---
# !!! è«‹å°‡æ‚¨çš„ YOLOv12 .pt æª”æ¡ˆæ”¾åœ¨ 'weights' è³‡æ–™å¤¾ä¸­ !!!
YOLO_WEIGHTS_PATH = "weights/best.pt"
# è‡ªå‹•æª¢æ¸¬è¨­å‚™
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# --- ç¡¬é«”é…ç½® ---
# !!! è«‹æ ¹æ“šæ‚¨çš„ç¡¬é«”é€£æ¥ä¿®æ”¹é€™äº›åƒæ•¸ !!!
# 'jetson_gpio' æˆ– 'custom' (ç¤ºæ„æ¨¡å¼)
ARM_PWM_LIB_TYPE = "jetson_gpio"
# BCM è…³ä½è™Ÿç¢¼: [base, shoulder, elbow, wrist_pitch, wrist_roll, special]
ARM_JOINT_PINS = [17, 18, 27, 22, 23, 24]
ARM_GRIPPER_PIN = 25

# 'gpio', 'serial', æˆ– 'custom' (ç¤ºæ„æ¨¡å¼)
CONVEYOR_CONTROL_TYPE = "gpio"
# å¦‚æœæ˜¯ 'gpio' æ¨¡å¼ï¼Œè¨­å®š GPIO è…³ä½
CONVEYOR_GPIO_PINS = {'forward': 13, 'enable': 19, 'sensor': 26} # ç¯„ä¾‹è…³ä½, è«‹æ›¿æ›
# å¦‚æœæ˜¯ 'serial' æ¨¡å¼ï¼Œè¨­å®šåºåˆ—åŸ 
CONVEYOR_SERIAL_PORT = '/dev/ttyUSB0' # or 'COM3' on Windows
CONVEYOR_BAUDRATE = 9600

# --- é‚è¼¯é…ç½® ---
# ç”¢å“é¡åˆ¥åˆ°æ©Ÿæ¢°æ‰‹è‡‚æ”¾ç½®å€åŸŸçš„æ˜ å°„
# !!! è«‹æ ¹æ“šæ‚¨æ¨¡å‹çš„é¡åˆ¥åç¨±é€²è¡Œä¿®æ”¹ !!!
PRODUCT_TO_ZONE_MAP = {
    "class_A": 1,
    "class_B": 2,
    "class_C": 3,
    "class_D": 4,
    "OK": 1,      # å‡è¨­ "OK" ç”¢å“æ”¾åˆ°å€åŸŸ 1
    "NG": 2,      # å‡è¨­ "NG" ç”¢å“æ”¾åˆ°å€åŸŸ 2
}
DEFAULT_ZONE_FOR_UNKNOWN = 0 # 0 ä»£è¡¨å»¢æ–™å€æˆ–ä¸åšè™•ç†

# --- å½±åƒå‰è™•ç†é…ç½® ---
PREPROCESSING_ENABLED = True # è¨­å®šç‚º True ä¾†å•Ÿç”¨å‰è™•ç†
HIGH_BOOST_K = 1.5 # é«˜å¢å¹…æ¿¾æ³¢çš„ k å€¼

# ======================================================================
# --- è‡ªå‹•åŒ–æµç¨‹å·¥ä½œç·šç¨‹ ---
# ======================================================================
class AutomationWorker(QThread):
    # --- ä¿¡è™Ÿå®šç¾© ---
    status_updated = pyqtSignal(QLabel, str, str)
    image_updated = pyqtSignal(QPixmap)
    log_added = pyqtSignal(list)
    stats_updated = pyqtSignal(dict)
    finished = pyqtSignal()

    def __init__(self, detector, conveyor, robot_arm):
        super().__init__()
        self.detector = detector
        self.conveyor = conveyor
        self.robot_arm = robot_arm
        self.is_running = False
        self.stats = {'total': 0, 'pass': 0, 'defect': 0}

    def _preprocess_image(self, input_path):
        """å°å½±åƒé€²è¡Œé‚Šç·£åµæ¸¬å’Œé«˜å¢å¹…æ¿¾æ³¢"""
        try:
            self.log_event("å½±åƒå‰è™•ç†ä¸­...", "info")
            img = cv2.imread(input_path)
            if img is None:
                self.log_event(f"è®€å–å½±åƒå¤±æ•—: {input_path}", "error")
                return input_path, False

            # 1. Canny é‚Šç·£åµæ¸¬ (ä¸»è¦ç”¨æ–¼è¦–è¦ºåŒ–æˆ–ä½œç‚ºä¸€å€‹ç‰¹å¾µ)
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 100, 200)

            # 2. é«˜å¢å¹…æ¿¾æ³¢ (High-Boost Filtering)
            # å‰µå»ºä¸€å€‹æ¨¡ç³Šç‰ˆæœ¬çš„å½±åƒ
            blurred = cv2.GaussianBlur(img, (7, 7), 0)
            # è¨ˆç®—é®ç½© (åŸå§‹å½±åƒ - æ¨¡ç³Šå½±åƒ)
            mask = cv2.subtract(img, blurred)
            # å°‡é®ç½©åŠ æ¬Šå¾ŒåŠ å›åˆ°åŸå§‹å½±åƒ
            high_boost_img = cv2.addWeighted(img, 1.0, mask, HIGH_BOOST_K, 0)

            # å»ºç«‹å„²å­˜ç›®éŒ„
            output_dir = "processed_images"
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)

            # å„²å­˜è™•ç†å¾Œçš„å½±åƒ
            filename = os.path.basename(input_path)
            output_path = os.path.join(output_dir, f"processed_{filename}")
            cv2.imwrite(output_path, high_boost_img)

            self.log_event("å½±åƒå‰è™•ç†å®Œæˆ", "success")
            return output_path, True
        except Exception as e:
            self.log_event(f"å½±åƒå‰è™•ç†å¤±æ•—: {e}", "error")
            return input_path, False

    def run(self):
        self.is_running = True
        while self.is_running:
            self.status_updated.emit(self.parent().ui.system_status, "ç³»çµ±ç‹€æ…‹ï¼šğŸŸ¢ é‹è¡Œä¸­", "green")

            # --- 1. ç­‰å¾…ç”¢å“ & å½±åƒæ“·å– ---
            self.log_event("ç­‰å¾…ç”¢å“è§¸ç™¼...", "info")
            time.sleep(1) # ç¤ºæ„ç­‰å¾…

            self.status_updated.emit(self.parent().ui.camera_status, "ç›¸æ©Ÿç‹€æ…‹ï¼šğŸŸ¡ æ“·å–ä¸­...", "orange")
            image_path = capture_image(output_dir="live_captured_images")
            if not image_path:
                self.log_event("å½±åƒæ“·å–å¤±æ•—", "error")
                self.status_updated.emit(self.parent().ui.camera_status, "ç›¸æ©Ÿç‹€æ…‹ï¼šğŸ”´ å¤±æ•—", "red")
                continue

            self.log_event(f"å½±åƒæ“·å–æˆåŠŸ: {os.path.basename(image_path)}", "info")
            self.status_updated.emit(self.parent().ui.camera_status, "ç›¸æ©Ÿç‹€æ…‹ï¼šğŸŸ¢ æ­£å¸¸", "green")

            # --- 2. å½±åƒå‰è™•ç† ---
            path_for_yolo = image_path
            if PREPROCESSING_ENABLED:
                processed_path, success = self._preprocess_image(image_path)
                if success:
                    path_for_yolo = processed_path

            # æ›´æ–° GUI ä¸Šçš„åœ–ç‰‡
            self.update_display_image(path_for_yolo)

            # --- 3. YOLO æ¨è«– ---
            self.log_event("YOLOv12 æ¨è«–ä¸­...", "info")
            detections = self.detector.detect(path_for_yolo)
            self.stats['total'] += 1

            if not detections:
                self.log_event("æœªåµæ¸¬åˆ°ä»»ä½•ç‰©ä»¶", "warning")
                self.stats['pass'] += 1 # å‡è¨­æ²’åµæ¸¬åˆ°=è‰¯å“
                self.update_stats_display()
                continue

            # --- 4. è™•ç†åµæ¸¬çµæœ ---
            best_detection = detections[0]
            label = best_detection['label']
            confidence = best_detection['confidence']
            self.log_event(f"åµæ¸¬åˆ°: {label} (ä¿¡å¿ƒåº¦: {confidence:.2f})", "success")
            self.draw_detections_on_image(path_for_yolo, detections)

            # --- 5. æ±ºç­–èˆ‡ç¡¬é«”æ§åˆ¶ ---
            target_zone = PRODUCT_TO_ZONE_MAP.get(label, DEFAULT_ZONE_FOR_UNKNOWN)
            if target_zone == 0:
                self.log_event(f"æœªçŸ¥é¡åˆ¥ '{label}'ï¼Œç§»è‡³å»¢æ–™å€", "warning")
                self.stats['defect'] += 1
            else:
                self.log_event(f"ç”¢å“ '{label}'ï¼Œç§»è‡³å€åŸŸ {target_zone}", "info")
                self.stats['pass'] += 1

            # --- 6. è¼¸é€å¸¶ç§»å‹• ---
            self.status_updated.emit(self.parent().ui.conveyor_status, "è¼¸é€å¸¶ç‹€æ…‹ï¼šğŸŸ¡ ç§»å‹•ä¸­...", "orange")
            if self.conveyor.move_to_pickup_point():
                self.log_event("ç”¢å“å·²åˆ°é”å¤¾å–é»", "info")
                self.status_updated.emit(self.parent().ui.conveyor_status, "è¼¸é€å¸¶ç‹€æ…‹ï¼šğŸŸ¢ åœæ­¢", "green")
            else:
                self.log_event("ç”¢å“ç§»å‹•å¤±æ•—", "error")
                self.status_updated.emit(self.parent().ui.conveyor_status, "è¼¸é€å¸¶ç‹€æ…‹ï¼šğŸ”´ éŒ¯èª¤", "red")
                continue

            # --- 7. æ©Ÿæ¢°æ‰‹è‡‚å‹•ä½œ ---
            self.status_updated.emit(self.parent().ui.servo_status, "ä¼ºæœæ§åˆ¶ï¼šğŸŸ¡ å‹•ä½œä¸­...", "orange")
            self.robot_arm.pickup_object()
            self.robot_arm.place_object_in_zone(target_zone)
            self.status_updated.emit(self.parent().ui.servo_status, "ä¼ºæœæ§åˆ¶ï¼šğŸŸ¢ å°±ç·’", "green")

            self.update_stats_display()
            time.sleep(2)

        self.finished.emit()

    def stop(self):
        self.is_running = False

    def log_event(self, message, level):
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_map = {"info": "è¨Šæ¯", "success": "æˆåŠŸ", "warning": "è­¦å‘Š", "error": "éŒ¯èª¤"}
        self.log_added.emit([timestamp, log_map.get(level, "æœªçŸ¥"), message, ""])

    def update_display_image(self, image_path):
        pixmap = QPixmap(image_path)
        self.image_updated.emit(pixmap)

    def draw_detections_on_image(self, image_path, detections):
        img = cv2.imread(image_path)
        for det in detections:
            label, confidence, bbox = det['label'], det['confidence'], det['bbox']
            x1, y1, x2, y2 = bbox
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(img, f"{label} {confidence:.2f}", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

        rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb_image.shape
        qt_image = QImage(rgb_image.data, w, h, ch * w, QImage.Format_RGB888)
        self.image_updated.emit(QPixmap.fromImage(qt_image))

    def update_stats_display(self):
        self.stats['rate'] = (self.stats['pass'] / self.stats['total'] * 100) if self.stats['total'] > 0 else 0
        self.stats_updated.emit(self.stats)

# ======================================================================
# --- ä¸»è¦–çª— ---
# ======================================================================
class PCBAMainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.ui = PCBAUIInterface(self)
        self.init_modules()
        self.ui.connect_signals(self)
        self.is_conveyor_on = False

    def init_modules(self):
        self.update_status_label(self.ui.system_status, "ç³»çµ±ç‹€æ…‹ï¼šğŸŸ¡ åˆå§‹åŒ–ä¸­...", "orange")

        if not os.path.exists(YOLO_WEIGHTS_PATH):
            self.update_status_label(self.ui.system_status, f"ç³»çµ±ç‹€æ…‹ï¼šğŸ”´ éŒ¯èª¤ - æ‰¾ä¸åˆ°æ¨¡å‹", "red")
            self.detector = None
        else:
            self.detector = YOLOv12Detector(weights_path=YOLO_WEIGHTS_PATH, device=DEVICE)

        self.conveyor = ConveyorControl(port=CONVEYOR_SERIAL_PORT, baudrate=CONVEYOR_BAUDRATE,
                                     control_pins=CONVEYOR_GPIO_PINS, control_type=CONVEYOR_CONTROL_TYPE)
        self.conveyor.connect()

        self.robot_arm = RobotArmControl(joint_pins=ARM_JOINT_PINS, gripper_pin=ARM_GRIPPER_PIN,
                                       pwm_lib_type=ARM_PWM_LIB_TYPE)

        self.worker = AutomationWorker(self.detector, self.conveyor, self.robot_arm)
        self.worker.setParent(self)
        self.worker.status_updated.connect(self.update_status_label)
        self.worker.image_updated.connect(self.update_image_display)
        self.worker.log_added.connect(self.add_log_entry)
        self.worker.stats_updated.connect(self.update_stats)
        self.worker.finished.connect(self.on_worker_finished)

        self.update_status_label(self.ui.system_status, "ç³»çµ±ç‹€æ…‹ï¼šğŸŸ¢ å°±ç·’", "green")
        print("æ‰€æœ‰æ¨¡çµ„åˆå§‹åŒ–å®Œæˆã€‚")

    def start_auto_detection(self):
        if self.detector is None:
            print("ç„¡æ³•å•Ÿå‹•ï¼ŒYOLO æ¨¡å‹æœªè¼‰å…¥ã€‚")
            return
        if not self.worker.isRunning():
            self.ui.start_btn.setEnabled(False)
            self.ui.stop_btn.setEnabled(True)
            self.worker.start()

    def stop_auto_detection(self):
        if self.worker.isRunning():
            self.worker.stop()
            self.update_status_label(self.ui.system_status, "ç³»çµ±ç‹€æ…‹ï¼šğŸŸ¡ åœæ­¢ä¸­...", "orange")

    def on_worker_finished(self):
        self.ui.start_btn.setEnabled(True)
        self.ui.stop_btn.setEnabled(False)
        self.update_status_label(self.ui.system_status, "ç³»çµ±ç‹€æ…‹ï¼šğŸ”´ åœæ­¢", "red")
        self.conveyor.stop()
        self.robot_arm.move_to_named_position("home")

    def update_threshold(self, value):
        conf = value / 100.0
        self.ui.threshold_value.setText(f"{conf:.2f}")
        if self.detector:
            self.detector.conf_thres = conf

    def update_servo(self, value):
        self.ui.servo_value.setText(f"{value}Â°")
        self.robot_arm.set_joint_angle(0, value - 90)

    def toggle_conveyor(self):
        if self.is_conveyor_on:
            self.conveyor.stop()
            self.ui.conveyor_btn.setText("â–¶ï¸ å•Ÿå‹•è¼¸é€å¸¶")
            self.update_status_label(self.ui.conveyor_status, "è¼¸é€å¸¶ç‹€æ…‹ï¼šğŸŸ¢ åœæ­¢", "green")
        else:
            self.conveyor.start_forward()
            self.ui.conveyor_btn.setText("â¸ï¸ åœæ­¢è¼¸é€å¸¶")
            self.update_status_label(self.ui.conveyor_status, "è¼¸é€å¸¶ç‹€æ…‹ï¼šğŸŸ¡ ç§»å‹•ä¸­...", "orange")
        self.is_conveyor_on = not self.is_conveyor_on

    def reset_system(self):
        self.conveyor.stop()
        self.robot_arm.move_to_named_position("home")
        self.update_status_label(self.ui.system_status, "ç³»çµ±ç‹€æ…‹ï¼šğŸŸ¢ å°±ç·’", "green")

    def closeEvent(self, event):
        self.stop_auto_detection()
        self.worker.wait()
        self.conveyor.disconnect()
        self.robot_arm.cleanup()
        event.accept()

    def update_status_label(self, label, text, color):
        label.setText(text)
        label.setStyleSheet(f"color: {color}; font-weight: bold;")

    def update_image_display(self, pixmap):
        scaled_pixmap = pixmap.scaled(self.ui.image_display.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)
        self.ui.image_display.setPixmap(scaled_pixmap)

    def add_log_entry(self, log_data):
        row_pos = self.ui.log_table.rowCount()
        self.ui.log_table.insertRow(row_pos)
        for col, data in enumerate(log_data):
            self.ui.log_table.setItem(row_pos, col, QTableWidgetItem(str(data)))
        self.ui.log_table.scrollToBottom()

    def update_stats(self, stats):
        self.ui.total_label.setText(f"ç¸½æª¢æ¸¬æ•¸ï¼š{stats['total']}")
        self.ui.pass_label.setText(f"åˆæ ¼æ•¸ï¼š{stats['pass']}")
        self.ui.defect_label.setText(f"ç¼ºé™·æ•¸ï¼š{stats['defect']}")
        self.ui.pass_rate_label.setText(f"åˆæ ¼ç‡ï¼š{stats['rate']:.2f}%")


if __name__ == '__main__':
    for folder in ["live_captured_images", "processed_images", "weights"]:
        if not os.path.exists(folder):
            os.makedirs(folder)
    if not os.path.exists(YOLO_WEIGHTS_PATH):
         print(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ°æ¨¡å‹ '{YOLO_WEIGHTS_PATH}'ã€‚è«‹å°‡æ¬Šé‡æª”æ¡ˆæ”¾å…¥ 'weights' è³‡æ–™å¤¾ã€‚")

    app = QApplication(sys.argv)
    window = PCBAMainWindow()
    window.show()
    sys.exit(app.exec_())
